---
title: "Kafka Streams 그리고 Kafka Streams DSL, Processor API"
excerpt: 

categories:
    - Kafka
tags:
    - Kafka
last_modified_at: 2021-07-31T11:06:00-10:00
sitemap :
  changefreq : daily
  priority : 1.0
--- 

# Kafka Streams란 무엇인가
카프카 스트림즈는 카프카 클러스터내의 토픽에 저장된 데이터를 실시간으로 처리(변환) 분석을 하게 해주는 라이브러리이다. 즉 카프카 클러스터 내에서 메세지 파이프라인을 구축하게 해주는 것이다. 이러한 카프카 스트림즈는 기존 시스템이나 카프카에 대한 의존성없이 실행된다. 카프카 스트림즈는 가벼운 클라이언트 라이브러리이기 때문에 기존 자바 어플리케이션에서 쉽게 사용가능하다. 또한 이러한 카프카 스트림즈는 카프카 클러스터에서 장애가 발생하더라도 정호가히 한번 처리할 수 있는 fault tolerant system을 가지고 있다. 이러한 카프카 스트림즈를 데이터 처리를 위해 어플리케이션으로 만들어 활용하는데 이러한 카프카 스트림즈 어플리케이션은 JVM위에서 하나의 프로세스로 작동한다.

카프카 클러스터, 프로듀서, 컨슈머가 작동하는 환경에서 카프카 스트림즈 어플리케이션은 클러스터 내에서 자체적인 데이터 파이프라인을 구성한다.

<img width="922" alt="스크린샷 2021-08-02 오전 12 49 12" src="https://user-images.githubusercontent.com/61309514/127777163-41731c8a-2760-402b-9662-e31a0c419c8e.png">

스트림즈 어플리케이션은 내부적으로 스레드를 생성하고 이 스레드 마다 각각 실제로 데이터를 처리하는 태스크를 가진다. 1개의 스레드 당 1개 이상의 태스크를 가진다. 이러한 태스크는 데이터가 저장되어있는 토픽의 파티션 1개당 1개씩 만들어진다. 이러한 구조가 가능한 이유는 카프카 스트림즈 API가 내부적으로 컨슈머 API를 통해 구현되어있기 때문이다.

카프카 스트림즈를 이해하기 위해서 토폴로지에 대한 개념을 알아야하는데 토폴로지는 2개 이상의 노드들과 엣지들로 이루어진 노드-엣지들의 집합이다. 카프카 스트림즈에서는 토폴로지를 이루는 노드를 하나의 프로세서라고 부르고 엣지를 스트림이라고 부른다. 스트림은 토픽에 저장된 레코드를 의미한다.

프로세서는 소스 프로세서, 스트림 프로세서, 싱크 프로세서가 있는데 소스 프로세서는 데이터를 토픽에서 가져오는 역할을 하고 스트림 프로세서는 데이터를 처리하는 역할을 한다. 싱크 프로세서는 데이터를 토픽에 저장하는 역할을 한다.

즉 카프카 스트림즈에서 선언된 토폴로지에 따라 데이터들은 프로세서를 통해 제어되고 프로세서들은 엣지들로 연결되어있는데 이러한 엣지들은 한 프로세서에서 다음 프로세서로 데이터가 넘어가는 길을 의미한다.

이러한 스트림즈 어플리케이션은 스트림즈DSL 또는 프로세서 API를 통해 만들 수 있다.

# Kafka Streams DSL
kafka Streams DSL은 kafka에서 Streams Processor API를 활용해 미리 구현해 놓은 데이터 프로세싱 API이다. 보통 초보자나 대부분의 유저들에게 권장된다. 이러한 카프카 DSL은 레코드의 흐름 즉 스트림을 추상화한 KStream, KTable, GlobalKTable을 제공한다. Kafka Streams DSL에서는 서로 다른 싱크 프로세서로 부터 만들어진 KStream, KTable, GlobalKTable 끼리 join을 할 수 있다.

Kafka Streams DSL을 구현할때는 소스 프로세서에서 stream 메소드를 사용하고 싱크 프로세서에서 to 메소드를 활용한다. 중간의 스트림 프로세서는 filter 메소드를 사용해 특정 조건에 맞는 데이터를 골라낼 수 있다.

## KStream
KStream은 레코드의 흐름을 표현한 것으로 메세지와 키로 구성되어있다. KStream으로 데이터를 조회하면 토픽에 존재하는 모든 레코드들이 출력됩니다.

## Ktable
KTable은 메세지 키를 기준으로 레코드를 묶어서 사용한다. KTable은 유일한 메세지 키를 기준으로 가장 최신으로 입력된 레코드를 해당 키의 value값으로 지정한다. 이는 업데이트를 구현하기 위함이다. 또한 KTable로 선언된 토픽은 1개의 파티션이 1개의 태스크에 할당된다.


## GlobalKTable
GlobalKTable은 Ktable과 동일하게 레코드의 키를 기준으로 그룹핑된다. 그러나 KTable의 경우 KTable로 선언된 토픽이 1개의 파티션에 1개의 태스크가 할당된다는 것과는 다르게 모든 파티션 데이터가 모든 태스크에 할당된다는 차이가 있다. 이러한 특징으로 인해 KStream은 KTable과 파티션의 개수와 전략이 동일한 경우에만 join이 가능한데 GlobalKTable은 그런 제약 없이 조인이 가능하다.

# Kafka Processor API

프로세서 API는 스트림즈 DSL처럼 미리 정의된 메서드들 없이 프로그래머가 직접 로직을 담은 메서드를 구현해야하는 차이점이 있다. 프로세서 API는 스트림즈DSL에서 사용한 KStream, KTable, GlobalKTable 개념이 없다.
<br>
<br>
출처: 

아파치카프카 애플리케이션 프로그래밍 with 자바

카프카, 데이터 플랫폼의 최강자