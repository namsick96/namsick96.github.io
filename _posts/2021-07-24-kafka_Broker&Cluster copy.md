---
title: "Kafka Broker & Cluster"
excerpt: 

categories:
    - Kafka
tags:
    - Kafka
last_modified_at: 2021-07-24T11:06:00-10:00
sitemap :
  changefreq : daily
  priority : 1.0
--- 

# Kafka Broker, Kafka Cluster
카프카 브로커는 카프카 프로듀서,컨슈머와 데이터를 주고 받는 카프카 클러스터를 구성하는 주체입니다. 카프카 브로커는 카프카 클러스터를 구성하는데 일반적으로 3개의 브로커를 1개의 클러스터로 구성합니다. 1개의 브로커로 클러스터 구성이 가능하긴 하지만 데이터 분산 처리와 내고장성을 위해 최소 3개의 브로커로 1개의 클러스터를 구성합니다. 그리고 이러한 브로커들로 이루어진 카프카 클러스터의 메타데이터는 주키퍼에 의해 관리됩니다. 이러한 클러스터 내의 전체 브로커들이 클러스터에서 작동하는 과정을 관리하는 코디네이터 역할을 브로커 중 하나가 맡아서 수행합니다. 이러한 코디네이터는 카프카 브로커에 연결된 컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭 되도록 연결하고 만약 매칭되지 않은 파티션이 있을 경우(컨슈머의 탈락, 삭제 등등 외부적인 요인에 의해) 리밸런싱 작업을 해주기도 합니다.

## Kafka Broker의 작동

카프카 브로커의 작동은 다음과 같습니다. 프로듀서로 부터 데이터를 전달 받으면 카프카 브로커는 프로듀서에서 지정한 토픽에 해당하는 파티션에 레코드(이제부터 데이터를 레코드라고 하겠습니다)를 넣습니다. 이렇게 파티션에 저장된 레코드는 브로커가 있는 컴퓨터의 파일 시스템에 저장됩니다. 이렇게 파일 시스템에 레코드를 저장할 경우 속도 문제가 발생하는게 일반적이지만 카프카는 페이지 캐시를 사용해 파일 시스템의 입출력 속도를 높여 이 문제를 해결하였습니다.

## 카프카 Broker Controller 그리고 Replication

카프카 브로커는 브로커 간의 데이터 replication이 수행되기도 합니다. 이러한 replication 즉 복제는 내고장성을 충족시키기 위함이기도 합니다. 그렇다면 이러한 브로커 간의 replication 통제는 누가 할까요? 그건 카프카 브로커중 하나가 맡는 컨트롤러가 처리를 합니다. 카프카 클러스터에 소속된 브로커중 1개가 전체 클러스터의 컨트롤러 역할을 합니다. 이러한 컨트롤러는 만약 브로커가 클러스터에서 탈락되는 경우( 고장, 다른 이슈.. 등등) 해당 브로커에 존재하는 리더 파티션을 다른 브로커로 재분배 합니다. 또한 컨트롤러 역할을 하는 브로커가 문제가 생길 경우 다른 브로커가 컨트롤러 역할을 승계받습니다.

이렇게 카프카 브로커에서 레코드들은 서로 다른 브로커에 속해 있는 파티션으로 복제 됩니다. 이는 일부 브로커에 문제가 생겨도 데이터를 유실하지 않게 만들기 위함입니다. 이러한 파티션의 복제는 토픽을 생성할 때 파티션 복제 개수를 설정하여 지정할 수 있습니다. 만약 설정하지 않으면 브로커에 저장된 디폴트 값으로 작동합니다.

파티션 데이터의 복제는 다음과 같이 수행됩니다. 우선 리더 파티션이 존재합니다. 리더 파티션은 프로듀서, 컨슈머와 직접적으로 통신하는 파티션입니다. 그리고 팔로워 파티션이 존재합니다. 팔로워 파티션은 리더 파티션의 데이터를 복제한 파티션입니다. 팔로워 파티션은 리더 파티션이 가지고 있는 레코드, 오프셋을 가져와서 복제합니다. 이러한 복제로 인해서 저장 용량을 더 많이 차지한다는 단점이 있지만 만약 리더 파티션이 사용 불가 상태가 되었을 경우 다른 팔로워 파티션중 하나가 리더 파티션이 되어 중단 없이 작업을 수행할 수 있다는 장점이 있습니다.

## Kafak Broker의 데이터 삭제
kafka broker에 저장된 데이터를 삭제하는 방법은 브로커에 직접 접속해서 데이터를 삭제하는 것 뿐입니다. 이러한 데이터 삭제는 파일 단위로 이루어집니다. 브로커는 입력된 파일을 Log segment 단위로 저장을 해놓습니다. 이러한 log segment를 나누는 기준은 log.segment.bytes(용량 단위), log.segment.ms(시간 단위)로 설정할 수 있습니다. 브로커에 입력된 데이터를 위에 언급한 두 기준에 따라서 설정된 기준에 다다르면 파일 형태로 저장합니다. 이렇게 만들어진 파일은 log.retention.bytes, log.retention.ms 기준을 넘으면 삭제됩니다.


## kafka Consumer offset
카프카 브로커는 consumer 그룹이 어디까지 데이터를 가져갔는지 확인 할 수 있는 offset을 관리합니다. 이러한 offset은 컨슈머 그룹이 데이터를 가져 간 후 commit을 함으로 업데이트가 됩니다. 이러한 offset은 __consumer__offset 이라는 브로커 내의 토픽에 저장됩니다. 컨슈머 그룹은 해당 토픽내에 저장된 offset값을 가지고 다음 레코드를 가져갑니다.

<br>
<br>
출처

1. 아파치카프카 애플리케이션 프로그래밍 with자바
2. 카프카 데이터플랫폼의 최강자
